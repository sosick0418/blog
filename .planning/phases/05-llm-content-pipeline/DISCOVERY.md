# LLM Content Pipeline Discovery

## Overview

Research findings for integrating LLM-powered product review generation into the Coupang affiliate auto-blog system. The goal is AI-generated Korean product reviews that convert readers to affiliate clicks.

## Provider Evaluation

### Requirements
- **Free tier priority** (project constraint)
- **Korean language support** (primary market)
- **API access** (for automation via n8n in Phase 6)
- **Content quality** sufficient for product reviews

### Option 1: Google Gemini API (Recommended)

**Model:** Gemini 2.5 Flash

**Pricing:**
- Free tier: 10 RPM, 250K TPM, 250 RPD (as of Dec 2025)
- Paid: $0.30/1M input, $2.50/1M output tokens

**Pros:**
- Genuinely free tier with commercial use allowed
- 1M token context window
- Good Korean language support
- No credit card required for free tier
- Fast response times (Flash model)

**Cons:**
- Free tier recently reduced (20 RPD for some models)
- Korean tokenization uses more tokens than English
- Rate limits may require careful batching

**Verdict:** Best for free tier usage. Start here.

### Option 2: OpenAI GPT

**Model:** GPT-4o-mini or GPT-5 nano

**Pricing:**
- No free tier (requires prepaid credits)
- GPT-5 nano: $0.05/$0.40 per 1M tokens (cheapest)
- GPT-4o-mini: Low cost tier

**Pros:**
- High quality output
- Good Korean support
- Reliable API

**Cons:**
- No free tier in 2025
- Requires payment method upfront

**Verdict:** Good fallback if Gemini limits are insufficient.

### Option 3: Claude API (Anthropic)

**Model:** Claude Haiku 4.5

**Pricing:**
- Small free credits for new accounts only
- Haiku: $1/$5 per 1M tokens

**Pros:**
- Excellent content quality
- Strong reasoning for product analysis

**Cons:**
- No sustained free tier
- Higher cost than alternatives

**Verdict:** Best quality but not free-tier viable.

### Option 4: Korean-Specific LLMs

**Models:** Motif (102B), EXAONE-3 (LG), HyperCLOVA X (Naver)

**Considerations:**
- Motif available on Hugging Face (free, self-hosted)
- Requires infrastructure to run large models
- Best Korean language understanding

**Verdict:** Overkill for this project. Self-hosting complexity not worth it.

## Recommendation

**Primary: Google Gemini 2.5 Flash API**
- Use free tier for development and initial production
- Upgrade to paid tier only if volume requires it
- Estimated cost: Free for ~100-250 posts/day

**Fallback: OpenAI GPT-5 nano**
- If Gemini rate limits become blocking
- Very low cost ($0.05/$0.40 per 1M tokens)

## Content Generation Strategy

### Post Structure (from sample-product-review.md)

```
## 제품 소개 (Product Introduction)
- Overview and key features
- Target users
- Competitive differentiation

## 장점 (Pros)
- 3-4 specific advantages with detail

## 단점 (Cons)
- 1-2 honest drawbacks

## 총평 (Overall Review)
- Summary recommendation
- Recommended/Not recommended audiences
```

### Prompt Engineering Approach

**System prompt:**
- Role: Korean product reviewer with affiliate marketing expertise
- Tone: Trustworthy, conversational, persuasive
- Length: 500-800 words per review
- Format: Markdown with Korean headings

**Input data:**
- Product name, price, category, image URL
- Optional: Product description from Coupang

**Output:**
- Complete markdown content (no frontmatter - already generated by scripts/generate-post.js)

### Quality Considerations

1. **Avoid AI detection patterns**
   - Vary sentence structure
   - Use specific Korean expressions
   - Include "personal experience" framing

2. **SEO optimization**
   - Natural keyword inclusion
   - Structured headings (H2, H3)
   - Meta description generation

3. **Conversion focus**
   - Clear call-to-action phrases
   - Benefit-focused language
   - Trust signals (honest cons section)

## Technical Integration

### API Client Module

Location: `src/_data/llm/`

**Files needed:**
- `config.js` - API keys, model selection
- `gemini.js` - Gemini API client
- `prompts.js` - System/user prompt templates
- `index.js` - Main content generation function

### Environment Variables

```bash
GEMINI_API_KEY=           # Google AI Studio API key
LLM_PROVIDER=gemini       # Provider selection (gemini|openai)
LLM_MODEL=gemini-2.5-flash # Model selection
```

### Content Generation Flow

```
Product Data (from Phase 4)
    |
    v
prompts.js (build prompt)
    |
    v
gemini.js (API call)
    |
    v
Generated Korean content
    |
    v
Merge with existing frontmatter
    |
    v
Complete blog post
```

## Rate Limit Management

### Gemini Free Tier Strategy

- 250 RPD = ~250 posts per day maximum
- Implement retry with exponential backoff
- Queue system for n8n batching (Phase 6)
- Cache generated content to avoid regeneration

## References

- [Google Gemini API Pricing](https://ai.google.dev/gemini-api/docs/pricing)
- [Gemini API Free Quota Guide](https://www.aifreeapi.com/en/posts/gemini-api-free-quota)
- [OpenAI API Pricing](https://platform.openai.com/docs/pricing)
- [Korean LLM Ecosystem](https://www.upstage.ai/blog/en/open-source-llm-and-the-ecosystem-of-korean-llm)

---
*Researched: 2026-01-15*
